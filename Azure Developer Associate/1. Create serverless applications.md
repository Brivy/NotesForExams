# Create serverless applications

This is the first chapter of the online Azure Developer Associate course.

Modules not summarized:

- Monitor GitHub events by using a webhook with Azure Functions. The only information explained in this chapter is about GitHub and what a webhook is. The thing is that we probably don't need GitHub. The other information about a webhook is that it's just a HTTP endpoint.
- Enable automatic updates in a web application using Azure Functions and SignalR Service. It's only about implementing SignalR, what is cool on it's own but there is not really some interesting information here.

## Choose the best Azure service to automate your business processes

Modern businesses run on multiple applications and services. How well your business runs can often be impacted by how efficiently you can distribute the right data to the right task. Automating this flow of data can streamline your business even further. Choosing the right technology for these critical data integrations and process automation is also an important consideration.

### The Azure service options breakdown

Implementing the technology:
  
- Business processes modeled in software are often called **workflows**.
- There are four different technologies that can be used to build and implement workflows that integrate with *multiple systems*:
  - Logic Apps
  - Microsoft Power Automate
  - WebJobs
  - Azure Functions
- They all have similarities:
  - Accepting inputs.
  - Running actions.
  - Including conditions.
  - Producing outputs.
  - Can start based on schedule or triggered by an external event.

There are two types of technologies to use:

- **Design-first**. Providing a user interface where you can draw out the workflow.
  - *Logic apps*: A service within Azure to automate, orchestrate, and integrate disparate components of a distributed application. Includes around 200 *connectors* so you can integrate with external services (like Twitter or Office 365 connectors).
  - *Microsoft Power Automate*: A service to create workflows even when you have no development or IT Pro experience. Because it's build upon *Logic Apps*, you have the same range of connectors and actions. They can be triggered in one of the following ways:
    - Automated.
    - Button.
    - Scheduled.
    - Business process

|                                  |                  Microsoft Power Automate                  |                                         Logic Apps                                        |
|:--------------------------------:|:----------------------------------------------------------:|:-----------------------------------------------------------------------------------------:|
|          Intended users          |            Office workers and business analysts            |                                   Developers and IT pros                                  |
|        Intended scenarios        |               Self-service workflow creation               |                               Advanced integration projects                               |
|           Design tools           |              GUI only. Browser and mobile app              |                Browser and Visual Studio designer. Code editing is possible               |
| Application Lifecycle Management | Power Automate includes testing and production environment | Logic Apps source code can be included in Azure DevOps and source code management systems |

- **Code-first**. Writing code to build something custom or gain more control over the performance of your workflow.
  - *WebJobs and the WebJobs SDK*: A cloud-based hosting service for web applications, mobile back-ends, and RESTful APIs. You can write these WebJobs in various programming languages (like python or PHP) but they only support ASP.NET / SDK 2.x; however SDK 3.x supports .NET Core. Using the .NET Core Framework, you can also use the classes *JobHostConfiguration* or *HostBuilder*. There are two kinds of WebJobs:
    - Continuous. Run in a continuous loop. For example, you could use a continuous WebJob to check a shared folder for a new photo.
    - Triggered. Run when you manually start them or on a schedule.
  - *Azure Functions*: A simple way for you to run small pieces of code in the cloud, without having to worry about the infrastructure required to host that code and where you only pay for the time it runs. It also supports a lot of other languages like Java and Javascript. Some templates that can be used:
    - HTTPTrigger.
    - TimerTrigger.
    - BlobTrigger.
    - CosmosDBTrigger.

|                                           |          Azure WebJobs         |           Azure Functions           |
|:-----------------------------------------:|:------------------------------:|:-----------------------------------:|
|            Supported languages            |   C# if using the WebJobs SDK  |  C#, Java, Javascript and many more |
|             Automatic scaling             |               No               |                 Yes                 |
|    Development and testing in a browser   |               No               |                 Yes                 |
|            Pay-per-use pricing            |               No               |                 Yes                 |
|        Integration with Logic Apps        |               No               |                 Yes                 |
|              Package managers             | NuGet if using the WebJobs SDK |            Nuget and NPM            |
| Can be part op an App Service application |               Yes              | Yes (hosted under App Service plan) |
|      Provide close control of JobHost     |               Yes              |                  No                 |

### Why choose which service

See also this diagram for choosing a service:
![Cool picture](Pictures/service-choice-flow-diagram.png)

## Create serverless logic with Azure Functions

Azure Functions is a key component of the serverless computing offering from Azure and enables you to run pieces of code or functions, written in the programming language of your choice, in the cloud.

### What is Azure Functions?

Using Azure Logic Apps and Azure Functions, you are actually using **Serverless computing**. Your business logic runs as functions and you don't have to manually provision or scale infrastructure.

Azure Functions allows developers to host business logic that can be executed without provisioning infrastructure while only being charged for the resources used. This has some benefits:

- Avoids over-allocation of infrastructure: Not using/paying for too much infrastructure.
- Stateless logic: Function instances are created and destroyed on demand (state can be saved however).
- Event driven: They run only in response to an event. No need to write code to watch queues, blobs, hubs, etc.
- Functions can be used in traditional compute environments: Should the needs of your app change, you can take your project and deploy it in a non-serverless environment.

But it also has some drawbacks:

- Execution time: There is a default timeout of 5 minutes with a maximum of 10. If you trigger and expect a HTTP request, this time is restricted to 2.5 minutes. Using **Durable Functions** allows you to orchestrate the executions of multiple functions without any timeout.
- Execution frequency: While scaling, only one function app instance can be created every 10 seconds, for up to 200 total instances. Different types of triggers have different scaling requirements, so research your choice of trigger and investigate its limits.

### Creating a Azure Function

Functions are hosted in an execution context called a **function app**. You define function apps to logically group and structure your functions and a compute resource in Azure. There are two decisions to be made:

- Choosing the **service plan**:
  - The *consumption service plan*: This is the plan that you choose when using the Azure serverless application platform and it comes with the automatic scaling and bills only when the functions are running.
  - The *Azure App Service plan*: Running functions continuously on a VM instead of using serverless computing. Can be used when your functions require more processing power or execution time than the Consumption plan can provide.
- Linking a **storage account** for internal operations like logging function executions and managing execution triggers. On the *Consumption service plan*, this is also where the function code and configuration file are stored.

Functions respond to triggers and each function should have one:

- Blob Storage: Starts a function when a new or updated blob is detected.
- Azure Cosmos DB: Start a function when inserts and updates are detected.
- Event Grid: Starts a function when an event is received from Event Grid.
- HTTP: Starts a function with an HTTP request.
- Microsoft Graph Events: Starts a function in response to an incoming webhook from the Microsoft Graph. Each instance of this trigger can react to one Microsoft Graph resource type.
- Queue Storage: Starts a function when a new item is received on a queue. The queue message is provided as input to the function.
- Service Bus: Starts a function in response to messages from a Service Bus queue.
- Timer: Starts a function on a schedule.

A trigger is a special type of input **binding** that has the additional capability of initiating execution. Each binding has a direction - your code reads data from input bindings, and writes data to output bindings. Each function can have zero or more bindings to manage the input and output data processed by the function. An example of such binding that has a queue as input and a storage table as output is as follows:

```json
{
  "bindings": [
    {
      "name": "order",
      "type": "queueTrigger",
      "direction": "in",
      "queueName": "myqueue-items",
      "connection": "MY_STORAGE_ACCT_APP_SETTING"
    },
    {
      "name": "$return",
      "type": "table",
      "direction": "out",
      "tableName": "outTable",
      "connection": "MY_TABLE_STORAGE_ACCT_APP_SETTING"
    }
  ]
}
```

Some final notes:

> - You can create Azure functions by template or a custom template.
> - You can test the Function by manual execution or by using **Test/Run** in the Azure portal.
> - You can monitor the Azure function by turning on **Application Insights**.
> - You can add logging to your application by using:
>   - context.log() in JavaScript
>   - log.LogInformation() in C#
>   - Write-Host in PowerShell
> - You can see Errors and Warnings in the same log window.

## Execute an Azure Function with triggers

Azure Functions app supports a feature called triggers. Triggers are used to determine how an Azure Function is invoked.

### Timer triggers

A timer trigger is a trigger that executes a function at a consistent interval. To create a timer trigger, you need to supply two pieces of information:

- **Timestamp parameter name**, which is simply an identifier to access the trigger in code.
- **A Schedule**, which is a CRON expression that sets the interval for the timer.

A CRON expression is a string that consists of six fields that represent a set of times. In Azure, this is as follows: `{second} {minute} {hour} {day} {month} {day of the week}`. The syntax is as follows:

| Special character |             Meaning            |                                          Example                                          |
|:-----------------:|:------------------------------:|:-----------------------------------------------------------------------------------------:|
|         *         | Selects every value in a field |                 An asterisk "*" in the day of week field means every day.                 |
|         ,         |    Separates items in a list   | A comma "1,3" in the day of week field means just Mondays (day 1) and Wednesdays (day 3). |
|         -         |        Specifies a range       |  A hyphen "10-12" in the hour field means a range that includes the hours 10, 11 and 12.  |
|         /         |     Specifies an increment     |        A slash "*/10" in the minutes field means an increment of every 10 minutes.        |

### HTTP triggers

An HTTP trigger is a trigger that executes a function when it receives an HTTP request. A HTTP trigger requires a *Programming language*, a *trigger name* and an *Authorization level*. Also one of the settings while creating a function is the **Request parameter name**. This setting is a string that represents the name of the parameter that contains the information about an incoming HTTP request. By default, the name of the parameter is req.

An HTTP trigger Authorization level is a flag that indicates whether an incoming HTTP request needs an API key for authentication. There are three Authorization levels:

- Function (key-based, needs *function* or *host* key)
- Anonymous (no key needed)
- Admin (key-based, needs *host* key)

There are two types of keys: *function* and *host*. A Function key is specific to a function while a Host key applies to all functions inside a function app.

### Blob triggers

Azure Blob storage is an object storage solution that's designed to store large amounts of unstructured data. It has three types of blobs:

- Block blobs: Storing text or binary data.
- Append blobs: Same as Block blobs, but are more designed for appending data (like logs)
- Page blobs: Designed for frequent random read and write operations.

 A blob trigger is a trigger that executes a function when a file is **uploaded or updated in Azure Blob storage**. To create a blob trigger, you create an Azure Storage account and provide a location that the trigger monitors.

While creating a blob trigger, there are certain important factors to keep in mind:

- Understanding **Path**. This tells the blob trigger where to monitor to see if a blob is uploaded or updated. The default value is: `samples-workitems/{name}`. This consists of two parts:
  - **samples-workitems** represents the blob container that the trigger monitors.
  - **{name}** means that every type of file will cause the trigger to invoke the function. In a real world example, this could look like this: `samples-workitems/{name}.png`.
- Understanding the text **name**. The name represents a parameter in your Azure function that receives the name of the added file.

## Chain Azure Functions together using input and output bindings

The power of Azure Functions comes mainly from the integrations that it offers with a range of data sources and services, which are defined with bindings. With bindings, developers interact with other data sources and services without worrying about how the data flows to and from their function.

### Explore input and output binding types

Bindings provide a declarative way to connect to data from within your code. They make it easier to integrate with data streams consistently in a function. There are also *triggers*, which are special types of input bindings that cause a function to run. 

There are two types of bindings you can use with functions:

- **Input binding**: Connects to a data source. Our function can read data from these inputs.
- **Output binding**: Connects to a data destination. Our function can write data to these destinations.

The type of binding defines where we are reading or sending data. A binding type can be an input, an output or both. Some of those are:

- Blob Storage
- Azure Service Bus Queues
- Azure Cosmos DB
- Azure Event Hubs
- External files
- External tables
- HTTP endpoints

While implementing such a binding, you'll need to define some properties:

- **Name**: Defines the function parameter through which you access the data (receives the content).
- **Type**: Identifies the type of binding (which data/service).
- **Direction**: Indicates the direction data is flowing (input/output).
- **Connection** (not always needed): Provides the name of an app setting key that contains the connection string.

To create a binding we have to create a *function.json* file. For example, this will look like the following:

```JSON
    {
      "name": "headshotBlob",
      "type": "blob",
      "path": "thumbnail-images/{filename}",
      "connection": "HeadshotStorageConnection",
      "direction": "in"
    },
```

Explanation of the JSON properties:

- *name*: Variable that holds the data
- *type*: Type of binding
- *path*: The specified path for a blob type (see last chapter)
- *connection*: Connection string setting name in the application settings file
- *direction*: Input or Output binding

### Explore input bindings

To connect to a data source, you have to configure an input binding. To create a binding as an input, **you must define the direction as `in`**. The parameters for each type of binding may vary.

To resolve values from various sources, you can use **binding expressions**.The expression is evaluated when the function is invoked to yield a value. Most expressions are identified by being wrapped in curly braces. However, app setting binding expressions are wrapped in percent signs rather than curly braces.

Here are a few examples:

- App settings
- Trigger filename
- Trigger metadata
- JSON payloads
- New GUID
- Current date and time

### Explore output bindings

You'll use output bindings when you want to send or store data. To create a binding as an output, **you must define the direction as `out`**.

There are a few examples:

- Blob Storage: You can use the blob output binding to write blobs.
- Azure Cosmos DB: The Azure Cosmos DB output binding lets you write a new document to an Azure Cosmos DB database using the SQL API.
- Event Hubs: Use the Event Hubs output binding to write events to an event stream. You must have send permission to an event hub to write events to it.
- HTTP: Use the HTTP output binding to respond to the HTTP request sender. This binding requires an HTTP trigger and allows you to customize the response associated with the trigger's request. This can also be used to connect to webhooks.

## Create a long-running serverless workflow with Durable Functions

Durable Functions is an extension of Azure Functions that enables you to perform long-lasting, stateful operations in Azure. Azure provides the infrastructure for maintaining state information. You can use Durable Functions to orchestrate a long-running workflow.

## What are Durable Functions?

Durable Functions enables you to implement complex stateful functions in a serverless-environment while being an extension of Azure Functions. The difference is that state will be kept in-between requests.

You can use it for:

- Writing event driven code.
- Chaining functions together so you can make them work in parallel.
- Orchestrating an coordinating functions.
- State is being saved.

To define stateful workflows, you can make use of an *orchestration function*. This provides extra benefits:

- Defining workflows in code instead of writing a JSON description.
- Functions can be called both synchronously and asynchronously.
- **Azure checkpoints** the progress of a function automatically when the function awaits. Azure may choose to dehydrate the function and save its state while the function waits, to preserve resources and reduce costs. When the function starts running again, Azure will rehydrate it and restore its state.

There are three types of durable functions:

- **Client** functions are the entry point for creating an instance of a Durable Functions orchestration. (any supported language)
- **Orchestrator** functions describe how actions are executed, and the order in which they are run. (C# or JavaScript)
- **Activity** functions are the basic units of work in a durable function orchestration. An activity function contains the actual work performed by the tasks being orchestrated.

### Patterns for using Durable Functions

You can use Durable Functions to implement common workflow patterns:

- **Function chaining** - In this pattern, the workflow executes a sequence of functions in a specified order. The output of one function is applied to the input of the next function in the sequence. The output of the final function is used to generate a result.

![Cool picture](Pictures/function-chaining.png)

- **Fan out/fan in** - This pattern runs multiple functions in parallel and then waits for all the functions to finish. The results of the parallel executions can be aggregated or used to compute a final result.

![Cool picture](Pictures/fan-out-fan-in.png)

- **Async HTTP APIs** - This pattern addresses the problem of coordinating state of long-running operations with external clients. An HTTP call can trigger the long-running action. Then, it can redirect the client to a status endpoint. The client can learn when the operation is finished by polling this endpoint.

![Cool picture](Pictures/async-http-api.png)

- **Monitor** - This pattern implements a recurring process in a workflow, possibly looking for a change in state. For example, you could use this pattern to poll until specific conditions are met.

![Cool picture](Pictures/monitor.png)

- **Human interaction** - This pattern combines automated processes that also involve some human interaction. Human interaction can be incorporated using timeouts and compensation logic that runs if the human fails to interact correctly within a specified response time. An approval process is an example of a process that involves human interaction.

![Cool picture](Pictures/approval.png)

### Comparing to Logic Apps

Azure Durable Functions is intended as a powerful serverless compute option to run custom logic. Azure Logic Apps is better suited for integrating Azure services and components. You can use either technology to create complex orchestrations. See the following table for more comparisons:

|     Task     |                             Azure Durable Functions                            |                                              Azure Logic Apps                                              |
|:------------:|:------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------:|
|  Development |                             Code-first (imperative)                            |                                         Design-first (declarative)                                         |
| Connectivity |  About a dozen built-in binding types. You can write code for custom bindings. | Large collection of connectors. Enterprise Integration Pack for B2B. You can also build custom connectors. |
|    Actions   | Each activity is an Azure Function. You write the code for activity functions. |        Large collection of ready-made actions. You integrate custom logic through custom connectors.       |
|  Monitoring  |                           Azure Application Insights                           |                                      Azure portal, Azure Monitor logs                                      |
|  Management  |                       REST API, PowerShell, Visual Studio                      |               Azure portal, REST API, PowerShell, Visual Studio, Visual Studio Code extension              |

## Develop, test, and publish Azure Functions by using Azure Functions Core Tools

The Azure Functions Core Tools are command-line utilities that enable you to develop and run functions locally and publish them to Azure.

### What is Core Tools

The Azure Functions Core Tools are a set of command-line tools that you can use to develop and test Azure Functions on your local computer. This is by using the keyword `func` in the command line. While there are two versions available (1.x and 2.x), it's recommended to use the newest version. And if you are using local development for Functions, you can't use the Azure portals editor anymore.

The main purpose of Core Tools is:

- Generate the files and folders you need to develop functions on your local computer
- Run your functions locally so you can test and debug them
- Publish your functions to Azure

### Developing with Core Tools

Every function published to Azure belongs to a **function app**: a collection of functions that are published together into the same environment. All of the functions in an app share a common set of configuration values, and must all be built for the same language runtime.

When you develop functions locally, you work within a **functions project**: a folder that contains the code and configuration files that define your functions. Every new function you add to the project requires additional code and configuration that must be complete and correctly structured, or your functions will not be able to run.

If you maintain this by yourself (say, create the folders etc.), it can get messy and complicated. For that reason, there is Core Tools.

- `func init` is a command that will create the *functions project*. This will always add two project files:
  - **host.json**: Stores runtime configuration values, such as logging options, for the function app that are used both when running locally and in Azure.
  - **local.settings.json**: Stores configuration values that only apply to the function app when it is run locally with the Core Tools. It contains *local runtime settings* (for configuring the local functions runtime) and *custom application settings* (can be accessed and used by all the functions in the app).
- `func new` is a command that will create a new function inside the functions project.
- `func start` is a command that starts the **functions host** locally (platform that makes sure everything outside the function code works like configuration, listen for triggers, etc.).
- `func azure functionapp publish <app_name>` is a command to publish a function to Azure where `<app_name>` stands for the name of the function app in Azure. Remember to keep an active connection to Azure by the Azure CLI or Azure PowerShell otherwise this won't work!

One last set of important stuff:

- No testing is done when publishing.
- Functions already present will be stopped => deleted => overwritten.
- No relationship is made with the local project and the one in Azure.
- The default authorization level is **function**.

## Develop, test, and deploy an Azure Function with Visual Studio

You follow a test-driven development process, so you're also required to write automated unit tests for the new services. You have a team of developers well-versed with Microsoft technologies, including the .NET framework and Visual Studio. You decide to investigate the use of Azure Functions to meet your requirements.

### Deployments

Azure Functions makes it easy to deploy your function app using App Service continuous integration with the **Deployment Center**. This enables a workflow where function code updates made by using one of these integrated services triggers deployment to Azure:

- Bitbucket
- Dropbox
- External repository (Git or Mercurial)
- Git local repository
- GitHub
- OneDrive
- Azure DevOps

You can also deploy from a **zip file** using the push deployment technique. The zip file contains the executable code for your functions. Zip deployment copies these files to the `wwwwroot` folder in the Azure Function App. You can perform zip deployment using the `functionapp deployment` command in the Azure CLI.

```bash

az functionapp deployment source config-zip \
-g <resource-group> \
-n <function-app-name> \
--src <zip-file>

```

## Expose multiple Azure Function apps as a consistent API by using Azure API Management

You can use Azure Functions and Azure API Management to build complete APIs with a microservices architecture.

Azure API Management (APIM) is a fully managed cloud service that you can use to publish, secure, transform, maintain, and monitor APIs. It enables you to create and manage modern API gateways for existing backend services no matter where they are hosted. Furthermore, It helps with:

- Publishing APIs
- Handling authentication and authorization
- Rate limiting the APIs
- Request and response transformation
- Logging and tracing
- Version management

If you want to use it with Azure Functions (or other microservices-based architectures and event-driven systems), you could use the **Consumption Tier**. This has:

- No infrastructure to manage
- No idle capacity
- High availability
- Automatic scaling
- Usage-based pricing

Composing an API using API Management has advantages that include:

- Client apps are coupled to the API expressing business logic, not the underlying technical implementation with individual microservices.
- API Management acts as an intermediary that forwards the request to the right microservice.
- You can use API Management policies to enforce consistent rules on all microservices in the product. For example, you can transform all XML responses into JSON, if that is your preferred format.
- Policies also enable you to enforce consistent security requirements.
- Easily test and monitor each microservice and its operations

**Note:** you can use import Azure Function Apps as new APIs or appending them te existing APIs. This process automatically generates a host key in the Azure Function App, which is then assigned to a named value in Azure API Management.

## Extra notes

Some extra notes that don't have their own chapter:

- Webhooks are user-defined HTTP callbacks. They're triggered by some event, such as pushing code to a repo or updating a wiki page. When the event occurs, the source site makes an HTTP request to the URL configured for the webhook. With Azure Functions, we can define logic in a function that can be run when a webhook message is received.
- Functions support CORS. CORS is an HTTP feature that enables a web application running under one domain to access resources in another domain. By editing `Host`section in the *local.settings.json* file, you can enable it:

```JSON

"Host" : {
    "LocalHttpPort": 7071,
    "CORS": "http://localhost:8080",
    "CORSCredentials": true
  }

```

- SignalR is an abstraction for a series of technologies that allows your app to enjoy two-way communication between the client and server. SignalR connections begin with a standard HTTP request. As the server evaluates the connection, the most appropriate communication method (transport) is selected. Transports are chosen depending on the APIs available on the client (WebSockets -> Server Sent Events -> Ajax long polling or Forever Frame (IE only)).
